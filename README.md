# ğŸ—„ï¸ AutomatizaciÃ³n de NormalizaciÃ³n de Bases de Datos (ETL con Docker)

![Python](https://img.shields.io/badge/Python-3.12-blue?style=for-the-badge&logo=python&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-336791?style=for-the-badge&logo=postgresql&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-ETL-150458?style=for-the-badge&logo=pandas&logoColor=white)

Este proyecto implementa un pipeline automatizado de **ETL (Extract, Transform, Load)** para normalizar conjuntos de datos "crudos" (CSV) hasta la **Tercera Forma Normal (3FN)**.

El sistema procesa archivos desnormalizados, limpia los datos, separa entidades, genera esquemas SQL relacionales y exporta los resultados, todo orquestado dentro de un entorno contenerizado con **Docker**.

## ğŸ“‹ DescripciÃ³n del Proyecto

El objetivo es resolver problemas comunes en bases de datos desnormalizadas (redundancia, anomalÃ­as de inserciÃ³n/borrado) mediante scripts de Python que transforman los datos automÃ¡ticamente.

### Datasets Procesados
El sistema maneja tres escenarios de datos reales obtenidos de Kaggle:
1.  **Netflix Movies & TV Shows:** SoluciÃ³n a listas multivaluadas (Actores, GÃ©neros) -> **1FN**.
2.  **E-commerce Sales:** EliminaciÃ³n de redundancia transaccional -> **2FN**.
3.  **Hospital Patient Records:** SeparaciÃ³n de dependencias transitivas (Doctores, Pacientes) -> **3FN**.

## ğŸš€ Arquitectura y TecnologÃ­as

El proyecto utiliza una arquitectura de microservicios con Docker Compose:

* **App (Python 3.12):** Ejecuta scripts con `pandas` para limpieza y normalizaciÃ³n. Genera archivos `.sql` (DDL/DML) y `.csv` limpios.
* **Database (PostgreSQL 15):** Servidor de base de datos que inicializa automÃ¡ticamente tres bases de datos independientes (`netflix`, `ecommerce`, `hospital`).
* **Interfaz (pgAdmin 4):** Cliente web para visualizar y administrar los datos.

## ğŸ“‚ Estructura del Repositorio

```text
normalizacion-db/
â”œâ”€â”€ docker-compose.yml      # OrquestaciÃ³n de servicios
â”œâ”€â”€ Dockerfile              # DefiniciÃ³n de imagen de Python ETL
â”œâ”€â”€ requirements.txt        # Dependencias (pandas, numpy)
â”œâ”€â”€ raw/                    # [ENTRADA] Archivos CSV originales (Fuente)
â”œâ”€â”€ sql/                    # [SALIDA] Scripts SQL generados automÃ¡ticamente
â”œâ”€â”€ data/
â”‚   â””â”€â”€ normalized/         # [SALIDA] Archivos CSV exportados por tabla
â”œâ”€â”€ scripts/                # LÃ³gica de NormalizaciÃ³n (CÃ³digo Fuente)
â”‚   â”œâ”€â”€ utils.py            # Funciones reutilizables (DRY)
â”‚   â”œâ”€â”€ normalize_netflix.py
â”‚   â”œâ”€â”€ normalize_ecommerce.py
â”‚   â””â”€â”€ normalize_hospital.py
â””â”€â”€ docker-entrypoint/      # Scripts de inicializaciÃ³n de BD
```
## ğŸ› ï¸ InstalaciÃ³n y Uso

Prerrequisitos:
-Docker Desktop instalado y ejecutÃ¡ndose.
-(Opcional) Git para clonar el repositorio.

Paso 1: Descargar el archivo .zip y descomprimir
Nota: AsegÃºrate de que los archivos .csv originales estÃ©n en la carpeta raw/.

Paso 2: Ejecutar con Docker
Levanta todo el entorno con un solo comando. Docker construirÃ¡ la imagen de Python, instalarÃ¡ las librerÃ­as y ejecutarÃ¡ los scripts.
```bash
docker compose up --build
```
Paso 3: Verificar Resultados
Una vez que la terminal muestre que los scripts han finalizado, puedes verificar:
Archivos SQL: Revisa la carpeta sql/ para ver el cÃ³digo generado.
CSVs Normalizados: Revisa la carpeta data/normalized/ para ver las tablas separadas.
Base de Datos: Accede a pgAdmin 4 desde tu navegador

## ğŸ–¥ï¸ Acceso a Servicios
Servicio,URL / DirecciÃ³n,Credenciales
pgAdmin 4 (Web),http://localhost:5050,Email: admin@admin.com  Pass: root
PostgreSQL (Externo),localhost:5433,User: admin_user  Pass: admin_password
PostgreSQL (Interno),Host: db Port: 5432,(Para configurar dentro de pgAdmin)

Nota: El puerto externo de PostgreSQL se configurÃ³ en 5433 para evitar conflictos con instalaciones locales en tu mÃ¡quina.

## ğŸ§  MetodologÃ­a de NormalizaciÃ³n
El script de Python aplica las siguientes reglas teÃ³ricas:
1FN (Atomicidad): Se identifican columnas con listas (ej. "Actor A, Actor B") y se utiliza explode() de Pandas para separar en registros Ãºnicos.
2FN (Dependencias Parciales): Se separan atributos que no dependen de la clave completa en tablas maestras (ej. Tabla Shows separada de Shows_Actors).
3FN (Dependencias Transitivas): Se crean catÃ¡logos independientes (ej. Countries, Genres) y se referencian mediante claves forÃ¡neas (IDs) para eliminar redundancia de texto.

## Hecho con ğŸ y â¤ï¸ para la clase de Bases de Datos.
